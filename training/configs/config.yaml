model:
  name: "mistralai/Mistral-7B-Instruct-v0.3"
  type: "mistral"
  max_length: 4096
  tokenizer_kwargs:
    trust_remote_code: true
  model_kwargs:
    trust_remote_code: true
    dtype: "bfloat16"

dataset:
  path: "data/conversations.json"
  tokenized_examples_path: "data/tokenized_examples.pt"
  train_split: 0.8
  val_split: 0.1
  test_split: 0.1
  random_seed: 42
  padding_side: "left"

training:
  epochs: 3
  batch_size: 16
  learning_rate: 2e-5
  eval_steps: 1000
  save_steps: 2000