model:
  name: "mistralai/Mistral-7B-Instruct-v0.3"
  type: "mistral"
  max_length: 4096
  tokenizer_kwargs:
    trust_remote_code: true
  model_kwargs:
    trust_remote_code: true
    dtype: "bfloat16"

dataset:
  path: "data/conversations.json"
  tokenized_examples_path: "data/tokenized_examples.pt"
  train_split: 0.8
  val_split: 0.15
  test_split: 0.05
  random_seed: 42
  padding_side: "left"

training:
  epochs: 2
  batch_size: 32
  gradient_accumulation_steps: 2
  learning_rate: 2e-5
  eval_steps: 500
  save_steps: 1000
  gradient_checkpointing: true
  dataloader_workers: 4