{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1e178976",
   "metadata": {},
   "source": [
    "### 00 Dataset Generation\n",
    "This notebook generates the dataset to be used for training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebb00c4c",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a06b8a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "\n",
    "import os\n",
    "os.chdir(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b094db69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "import uuid\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Optional, Tuple"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36946f0d",
   "metadata": {},
   "source": [
    "### Load raw text messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2172dce2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 783325 messages\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Chat Session</th>\n",
       "      <th>Message Date</th>\n",
       "      <th>Delivered Date</th>\n",
       "      <th>Read Date</th>\n",
       "      <th>Edited Date</th>\n",
       "      <th>Service</th>\n",
       "      <th>Type</th>\n",
       "      <th>Sender ID</th>\n",
       "      <th>Sender Name</th>\n",
       "      <th>Status</th>\n",
       "      <th>Replying to</th>\n",
       "      <th>Subject</th>\n",
       "      <th>Text</th>\n",
       "      <th>Attachment</th>\n",
       "      <th>Attachment type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hoganites</td>\n",
       "      <td>2024-02-11 23:37:26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>iMessage</td>\n",
       "      <td>Outgoing</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sent</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Guys</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hoganites</td>\n",
       "      <td>2024-02-11 23:37:30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>iMessage</td>\n",
       "      <td>Outgoing</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sent</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IMG_3206.PNG</td>\n",
       "      <td>Image</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hoganites</td>\n",
       "      <td>2024-02-11 23:37:33</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>iMessage</td>\n",
       "      <td>Outgoing</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sent</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>This can’t be real</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hoganites</td>\n",
       "      <td>2024-02-11 23:42:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-02-11 23:42:03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>iMessage</td>\n",
       "      <td>Incoming</td>\n",
       "      <td>+15627745147</td>\n",
       "      <td>Will Park</td>\n",
       "      <td>Read</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ew</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hoganites</td>\n",
       "      <td>2024-08-04 19:11:21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>iMessage</td>\n",
       "      <td>Outgoing</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sent</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>What day are ygs free to go to MGrill?</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Chat Session         Message Date Delivered Date            Read Date  \\\n",
       "0    hoganites  2024-02-11 23:37:26            NaN                  NaN   \n",
       "1    hoganites  2024-02-11 23:37:30            NaN                  NaN   \n",
       "2    hoganites  2024-02-11 23:37:33            NaN                  NaN   \n",
       "3    hoganites  2024-02-11 23:42:00            NaN  2024-02-11 23:42:03   \n",
       "4    hoganites  2024-08-04 19:11:21            NaN                  NaN   \n",
       "\n",
       "  Edited Date   Service      Type     Sender ID Sender Name Status  \\\n",
       "0         NaN  iMessage  Outgoing           NaN         NaN   Sent   \n",
       "1         NaN  iMessage  Outgoing           NaN         NaN   Sent   \n",
       "2         NaN  iMessage  Outgoing           NaN         NaN   Sent   \n",
       "3         NaN  iMessage  Incoming  +15627745147   Will Park   Read   \n",
       "4         NaN  iMessage  Outgoing           NaN         NaN   Sent   \n",
       "\n",
       "  Replying to Subject                                    Text    Attachment  \\\n",
       "0         NaN     NaN                                    Guys           NaN   \n",
       "1         NaN     NaN                                     NaN  IMG_3206.PNG   \n",
       "2         NaN     NaN                      This can’t be real           NaN   \n",
       "3         NaN     NaN                                      Ew           NaN   \n",
       "4         NaN     NaN  What day are ygs free to go to MGrill?           NaN   \n",
       "\n",
       "  Attachment type  \n",
       "0             NaN  \n",
       "1           Image  \n",
       "2             NaN  \n",
       "3             NaN  \n",
       "4             NaN  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_df = pd.read_csv(\"data/ryan_text_messages.csv\", dtype={\n",
    "    'Sender ID': str,\n",
    "    'Subject': str\n",
    "})\n",
    "\n",
    "print(f\"Loaded {len(raw_df)} messages\")\n",
    "raw_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebfd97b5",
   "metadata": {},
   "source": [
    "### Filter the messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "96e7eed5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original number of messages: 783,325\n",
      "Final message count: 750762\n"
     ]
    }
   ],
   "source": [
    "original_count = len(raw_df)\n",
    "\n",
    "EXCLUDED_WORDS = [\"nigger\", \"fuck\", \"shit\", \"nigga\", \"fag\", \"bitch\", \"chink\", \"retard\", \"bastard\", \"gay\", \"whore\"]\n",
    "\n",
    "df = raw_df.copy()\n",
    "\n",
    "print(f\"Original number of messages: {original_count:,}\")\n",
    "\n",
    "# Remove empty text Messages\n",
    "df = df[df['Text'].notna()]\n",
    "\n",
    "# Remove empty dates\n",
    "df = df[df['Message Date'].notna()]\n",
    "# Filter out messages that are just numbers (likely verification codes)\n",
    "is_verification_code = df['Text'].astype(str).str.match(r'^\\d{4,8}$')\n",
    "df = df[~is_verification_code]\n",
    "\n",
    "# Remove words that are excluded that I sent, and remove all outgoing messages with attachments\n",
    "pattern = '|'.join(EXCLUDED_WORDS)\n",
    "outgoing_mask = df['Type'] == 'Outgoing'\n",
    "text_lower = df['Text'].astype(str).str.lower()\n",
    "contains_excluded = text_lower.str.contains(pattern, na=False, regex=True)\n",
    "has_attachment = df['Attachment'].notna()\n",
    "\n",
    "# Keep all incoming messages OR outgoing messages that (don't contain excluded words AND don't have attachments)\n",
    "keep_mask = ~outgoing_mask | (outgoing_mask & ~contains_excluded & ~has_attachment)\n",
    "df = df[keep_mask]\n",
    "\n",
    "print(f\"Final message count: {len(df)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "714446df",
   "metadata": {},
   "source": [
    "### Tool Call Conversion Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "815b98bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tool call conversion functions loaded\n"
     ]
    }
   ],
   "source": [
    "REACTION_PATTERNS = {\n",
    "    \"Loved\": \"love\",\n",
    "    \"Liked\": \"like\",\n",
    "    \"Disliked\": \"dislike\",\n",
    "    \"Laughed at\": \"laugh\",\n",
    "    \"Emphasized\": \"emphasize\",\n",
    "    \"Questioned\": \"question\"\n",
    "}\n",
    "\n",
    "def detect_reaction(text: str) -> Optional[Dict[str, str]]:\n",
    "    \"\"\"Detect if text is a reaction message and extract reaction type and quoted text.\n",
    "    \n",
    "    Returns:\n",
    "        Dict with 'reaction_type' and 'quoted_text' if reaction detected, None otherwise\n",
    "    \"\"\"\n",
    "    if not text:\n",
    "        return None\n",
    "    \n",
    "    for reaction_label, reaction_type in REACTION_PATTERNS.items():\n",
    "        if text.startswith(reaction_label + \" \"):\n",
    "            quoted_match = re.search(r'[“](.*?)[”]', text)\n",
    "            if quoted_match:\n",
    "                quoted_text = quoted_match.group(1).strip()\n",
    "                return {\n",
    "                    'reaction_type': reaction_type,\n",
    "                    'quoted_text': quoted_text\n",
    "                }\n",
    "    \n",
    "    return None\n",
    "\n",
    "\n",
    "def find_message_by_text(\n",
    "    messages: List[Dict],\n",
    "    target_text: str,\n",
    "    start_idx: int,\n",
    "    guid_map: Dict[int, str],\n",
    "    target_speaker: Optional[str] = None,\n",
    "    target_timestamp: Optional[str] = None\n",
    ") -> Optional[str]:\n",
    "    \"\"\"Find message GUID by matching text (search backwards chronologically).\n",
    "    \n",
    "    Args:\n",
    "        messages: List of message dicts (in chronological order)\n",
    "        target_text: Text to match (may be truncated with ellipsis)\n",
    "        start_idx: Index to start searching backwards from\n",
    "        guid_map: Mapping of message indices to GUIDs\n",
    "        target_speaker: Optional speaker name to match\n",
    "        target_timestamp: Optional timestamp to match\n",
    "        \n",
    "    Returns:\n",
    "        GUID string if match found, None otherwise\n",
    "    \"\"\"\n",
    "    if not target_text:\n",
    "        return None\n",
    "    \n",
    "    target_text_clean = target_text.rstrip(\"…\").strip()\n",
    "    \n",
    "    if not target_text_clean:\n",
    "        return None\n",
    "    \n",
    "    for i in range(start_idx - 1, -1, -1):\n",
    "        if i >= len(messages):\n",
    "            continue\n",
    "        msg = messages[i]\n",
    "        \n",
    "        msg_text = msg.get('text', '')\n",
    "        if not msg_text or target_text_clean not in msg_text:\n",
    "            continue\n",
    "        \n",
    "        if target_speaker is not None:\n",
    "            msg_speaker = msg.get('speaker', '')\n",
    "            if msg_speaker != target_speaker:\n",
    "                continue\n",
    "        \n",
    "        if target_timestamp is not None:\n",
    "            msg_timestamp = msg.get('timestamp', '')\n",
    "            if msg_timestamp != target_timestamp:\n",
    "                continue\n",
    "        \n",
    "        return guid_map.get(i)\n",
    "    \n",
    "    return None\n",
    "\n",
    "def parse_replying_to_format(replying_to_str: str) -> Optional[Dict[str, str]]:\n",
    "    \"\"\"Parse replying_to formatted string to extract speaker, timestamp, and text.\n",
    "    \n",
    "    Format: \"➜ Replying to {speaker}, {timestamp}: « {text} »\"\n",
    "    \n",
    "    Returns:\n",
    "        Dict with 'speaker', 'timestamp', 'text' if parsed, None otherwise\n",
    "    \"\"\"\n",
    "    if not replying_to_str or not replying_to_str.strip():\n",
    "        return None\n",
    "    \n",
    "    pattern = r'➜ Replying to (.+?), (\\d{4}-\\d{2}-\\d{2} \\d{2}:\\d{2}:\\d{2}): « (.+?) »'\n",
    "    match = re.search(pattern, replying_to_str)\n",
    "    if match:\n",
    "        return {\n",
    "            'speaker': match.group(1).strip(),\n",
    "            'timestamp': match.group(2).strip(),\n",
    "            'text': match.group(3).strip()\n",
    "        }\n",
    "    \n",
    "    return None\n",
    "\n",
    "def convert_to_tool_call(msg: Dict, messages: List[Dict], msg_idx: int, guid_map: Dict[int, str]) -> Tuple[str, str, Optional[str]]:\n",
    "    \"\"\"Convert a message to tool call format.\n",
    "    \n",
    "    Returns:\n",
    "        Tuple of (tool_call_string, conversion_type, replying_to_guid)\n",
    "        conversion_type: 'reaction', 'reply', 'send_message', or 'failed'\n",
    "    \"\"\"\n",
    "    text = msg.get('text', '')\n",
    "    replying_to_str = msg.get('replying_to')\n",
    "    \n",
    "    reaction_info = detect_reaction(text)\n",
    "    if reaction_info:\n",
    "        quoted_text = reaction_info['quoted_text']\n",
    "        reaction_type = reaction_info['reaction_type']\n",
    "        \n",
    "        message_guid = find_message_by_text(messages, quoted_text, msg_idx, guid_map)\n",
    "        if message_guid:\n",
    "            tool_call = f'react(message_guid=\"{message_guid}\", reaction_type=\"{reaction_type}\")'\n",
    "            return tool_call, 'reaction', None\n",
    "        else:\n",
    "            tool_call = f'send_message(text={repr(text)})'\n",
    "            return tool_call, 'failed', None\n",
    "    \n",
    "    if replying_to_str:\n",
    "        replying_to_info = parse_replying_to_format(replying_to_str)\n",
    "        if replying_to_info:\n",
    "            replying_to_guid = find_message_by_text(\n",
    "                messages,\n",
    "                replying_to_info['text'],\n",
    "                msg_idx,\n",
    "                guid_map,\n",
    "                target_speaker=replying_to_info.get('speaker'),\n",
    "                target_timestamp=replying_to_info.get('timestamp')\n",
    "            )\n",
    "            if replying_to_guid:\n",
    "                tool_call = f'reply(message_guid=\"{replying_to_guid}\", text={repr(text)})'\n",
    "                return tool_call, 'reply', replying_to_guid\n",
    "    \n",
    "    tool_call = f'send_message(text={repr(text)})'\n",
    "    return tool_call, 'send_message', None\n",
    "\n",
    "def process_conversation_with_tool_calls(messages: List[Dict]) -> Tuple[List[Dict], Dict[str, int]]:\n",
    "    \"\"\"Process conversation messages to add tool calls and GUIDs.\n",
    "    \n",
    "    Failed conversions are filtered out (not included in output).\n",
    "    \n",
    "    Returns:\n",
    "        Tuple of (updated_messages_list, conversion_stats)\n",
    "    \"\"\"\n",
    "    stats = {\n",
    "        'total_outgoing': 0,\n",
    "        'reaction': 0,\n",
    "        'reply': 0,\n",
    "        'send_message': 0,\n",
    "        'failed': 0\n",
    "    }\n",
    "    \n",
    "    guid_map = {}\n",
    "    updated_messages = []\n",
    "    \n",
    "    for i, msg in enumerate(messages):\n",
    "        guid = str(uuid.uuid4()).upper()\n",
    "        guid_map[i] = guid\n",
    "        \n",
    "        if msg.get('type') == 'Outgoing':\n",
    "            stats['total_outgoing'] += 1\n",
    "            tool_call, conversion_type, replying_to_guid = convert_to_tool_call(msg, messages, i, guid_map)\n",
    "            \n",
    "            if conversion_type == 'failed':\n",
    "                stats['failed'] += 1\n",
    "                continue\n",
    "            \n",
    "            updated_msg = msg.copy()\n",
    "            updated_msg['guid'] = guid\n",
    "            updated_msg['tool_call'] = tool_call\n",
    "            stats[conversion_type] = stats.get(conversion_type, 0) + 1\n",
    "            \n",
    "            if replying_to_guid:\n",
    "                updated_msg['replying_to_guid'] = replying_to_guid\n",
    "            \n",
    "            updated_messages.append(updated_msg)\n",
    "        else:\n",
    "            updated_msg = msg.copy()\n",
    "            updated_msg['guid'] = guid\n",
    "            updated_msg['tool_call'] = None\n",
    "            updated_messages.append(updated_msg)\n",
    "    \n",
    "    return updated_messages, stats\n",
    "\n",
    "print(\"Tool call conversion functions loaded\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "031307c8",
   "metadata": {},
   "source": [
    "### Create conversations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c7f5667f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered out 1,228 conversations with no outgoing messages\n",
      "Created 1116 conversations\n",
      "Total messages: 747001\n",
      "\n",
      "Conversion Statistics:\n",
      "Total Outgoing Messages: 395558\n",
      "Reactions: 6538\n",
      "Replies: 9860\n",
      "Send Messages: 379156\n",
      "Failed Conversions (filtered out): 4\n",
      "\n",
      "Saved conversations to data/conversations.json\n"
     ]
    }
   ],
   "source": [
    "OUTGOING_SPEAKER_NAME = \"Ryan Amiri\"\n",
    "\n",
    "def parse_message_date(date_str):\n",
    "    \"\"\"Parse Message Date string to datetime object.\"\"\"\n",
    "    if pd.isna(date_str) or date_str == '':\n",
    "        return None\n",
    "    try:\n",
    "        return datetime.strptime(str(date_str).strip(), '%Y-%m-%d %H:%M:%S')\n",
    "    except (ValueError, TypeError):\n",
    "        return None\n",
    "\n",
    "def get_speaker_name(row):\n",
    "    \"\"\"Get speaker name for a message row.\"\"\"\n",
    "    if row['Type'] == 'Outgoing':\n",
    "        return OUTGOING_SPEAKER_NAME\n",
    "    else:\n",
    "        sender_name = row.get('Sender Name', '')\n",
    "        sender_id = row.get('Sender ID', '')\n",
    "        if pd.notna(sender_name) and str(sender_name).strip():\n",
    "            return str(sender_name).strip()\n",
    "        elif pd.notna(sender_id) and str(sender_id).strip():\n",
    "            return str(sender_id).strip()\n",
    "        else:\n",
    "            return 'Unknown'\n",
    "\n",
    "# Sort messages by date within each chat session\n",
    "df_sorted = df.copy().reset_index()\n",
    "df_sorted['_parsed_date'] = df_sorted['Message Date'].apply(parse_message_date)\n",
    "df_sorted = df_sorted.sort_values(['Chat Session', '_parsed_date', 'index'])\n",
    "df_sorted = df_sorted.drop(columns=['_parsed_date', 'index'])\n",
    "\n",
    "# Group by Chat Session and create conversations\n",
    "conversations = []\n",
    "filtered_out_count = 0\n",
    "\n",
    "total_stats = {\n",
    "    'total_outgoing': 0,\n",
    "    'reaction': 0,\n",
    "    'reply': 0,\n",
    "    'send_message': 0,\n",
    "    'failed': 0\n",
    "}\n",
    "\n",
    "for chat_session, group_df in df_sorted.groupby('Chat Session'):\n",
    "    # Filter out conversations with no outgoing messages (messages you sent)\n",
    "    has_outgoing = (group_df['Type'] == 'Outgoing').any()\n",
    "    if not has_outgoing:\n",
    "        filtered_out_count += 1\n",
    "        continue\n",
    "    \n",
    "    messages = []\n",
    "    \n",
    "    for _, row in group_df.iterrows():\n",
    "        message = {\n",
    "            'timestamp': row['Message Date'],\n",
    "            'type': row['Type'],\n",
    "            'speaker': get_speaker_name(row),\n",
    "            'text': str(row['Text']).strip(),\n",
    "            \"replying_to\": str(row['Replying to']).strip() if pd.notna(row.get('Replying to')) else None\n",
    "        }\n",
    "        messages.append(message)\n",
    "    \n",
    "    updated_messages, conv_stats = process_conversation_with_tool_calls(messages)\n",
    "    \n",
    "    for key in total_stats:\n",
    "        total_stats[key] += conv_stats.get(key, 0)\n",
    "    \n",
    "    conversations.append({\n",
    "        'chat_session': chat_session,\n",
    "        'message_count': len(updated_messages),\n",
    "        'messages': updated_messages\n",
    "    })\n",
    "\n",
    "if filtered_out_count > 0:\n",
    "    print(f\"Filtered out {filtered_out_count:,} conversations with no outgoing messages\")\n",
    "\n",
    "print(f\"Created {len(conversations)} conversations\")\n",
    "print(f\"Total messages: {sum(c['message_count'] for c in conversations)}\")\n",
    "\n",
    "print()\n",
    "print(\"Conversion Statistics:\")\n",
    "print(f\"Total Outgoing Messages: {total_stats['total_outgoing']}\")\n",
    "print(f\"Reactions: {total_stats['reaction']}\")\n",
    "print(f\"Replies: {total_stats['reply']}\")\n",
    "print(f\"Send Messages: {total_stats['send_message']}\")\n",
    "print(f\"Failed Conversions (filtered out): {total_stats['failed']}\")\n",
    "\n",
    "# Save to JSON\n",
    "output_path = Path(\"data/conversations.json\")\n",
    "output_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "with open(output_path, 'w', encoding='utf-8') as f:\n",
    "    json.dump(conversations, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print()\n",
    "print(f\"Saved conversations to {output_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee5ba722",
   "metadata": {},
   "source": [
    "### Transfer to HPC Cluster\n",
    "\n",
    "After generating the conversations.json file, transfer it to the HPC cluster:\n",
    "\n",
    "```bash\n",
    "rsync -avz --progress training/data/conversations.json amiri.ry@login.explorer.northeastern.edu:/projects/llpr/amiri.ry/projects/yap-for-me/training/data/\n",
    "```\n",
    "\n",
    "Or using scp:\n",
    "\n",
    "```bash\n",
    "scp training/data/conversations.json amiri.ry@login.explorer.northeastern.edu:/projects/llpr/amiri.ry/projects/yap-for-me/training/data/\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
